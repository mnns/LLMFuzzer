<div align="center">

# üß† LLMFuzzer - Fuzzing Framework for Large Language Models üß†

![LLMFuzzer-shell](https://github.com/mnns/LLMFuzzer/assets/1796080/71b006df-706c-43f6-acd1-49646dbcb0e5)

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Stars](https://img.shields.io/github/stars/mnns/LLMFuzzer)
![Forks](https://img.shields.io/github/forks/mnns/LLMFuzzer)
![Issues](https://img.shields.io/github/issues/mnns/LLMFuzzer)


[![forthebadge](https://forthebadge.com/images/badges/built-with-love.svg)](https://forthebadge.com)
[![forthebadge](https://forthebadge.com/images/badges/contains-cat-gifs.svg)](https://forthebadge.com)
[![forthebadge](https://forthebadge.com/images/badges/not-a-bug-a-feature.svg)](https://forthebadge.com)
</div>

LLMFuzzer is the first open-source fuzzing framework specifically designed for Large Language Models (LLMs), especially for their integrations in applications via LLM APIs. üöÄüí•

## üéØ Who is this for?

If you're a security enthusiast, a pentester, or a cybersec researcher who loves to find and exploit vulnerabilities in AI systems, LLMFuzzer is the perfect tool for you. It's built to make your testing process streamlined and efficient. üïµÔ∏è‚Äç‚ôÄÔ∏è

![Untitled](https://github.com/mnns/LLMFuzzer/assets/1796080/a143897d-383c-4ed9-8b2f-65f4cdc5aa63)

## üåü Features

- Robust fuzzing for LLMs üß™
- LLM API integration testing üõ†Ô∏è
- Wide range of fuzzing strategies üåÄ
- Modular architecture for easy extendability üìö

## üöÄ Get Started

1. Clone the repo
```bash
git clone https://github.com/mnns/LLMFuzzer.git
```

2. Navigate to the project directory
```bash
cd LLMFuzzer
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

4. Edit **llmfuzzer.cfg** with your LLM API endpoint (LLMFuzzer -> Your Application -> LLM)
```bash
Connection: 
  Type: HTTP-API
  Url: "http://localhost:3000/chat" # Your LLM API
  Content: JSON
  Query-Attribute: "query" # Your JSON query attribute
  Output-Attribute: "answer" # Your JSON response attribute
  Headers: {'enwiki_session': '17ab96bd8ffbe8ca58a78657a918558'} # Add HTTP Headers if needed 
  Cookie: {'enwiki_session': '17ab96bd8ffbe8ca58a78657a918558'} # Add Cookies if needed
```

5. Run LLMFuzzer
```bash
python main.py
```

## üî• Roadmap
* Adding more attacks
* HTML Report as output
* Multiple Connectors (JSON-POST, RAW-POST, QUERY-GET)
* Multiple Comparers
* Proxy Support
* Dual-LLM (Side LLM observation)
* Autonomous Attack Mode

## üìö Documentation
We are working on full documentation. It will cover detailed information about the architecture, different fuzzing strategies, examples, and how to extend the tool.

## ü§ù Contributing
We welcome all contributors who are passionate about improving LLMFuzzer. See our contributing guidelines for ways to get started. ü§ó

## üíº License
LLMFuzzer is licensed under the MIT License. See the LICENSE file for more details.

## üé© Acknowledgments
LLMFuzzer couldn't exist without the community. We appreciate all our contributors and supporters. Let's make AI safer together! üíñ

